{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f32570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d1a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "tf.random.set_seed(7)\n",
    "\n",
    "# Load the IMDB dataset\n",
    "top_words = 5000  # Vocabulary size\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96da45d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure uniform length\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8632e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(glove_file_path, word_index, embedding_dim=100):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    \n",
    "    embedding_matrix = np.zeros((top_words, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i < top_words:\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a41a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Download GloVe embeddings (e.g., glove.6B.100d.txt) and specify the path\n",
    "# For this example, assume glove.6B.100d.txt is in the working directory\n",
    "glove_path = 'glove.6B.100d.txt'\n",
    "embedding_dim = 100\n",
    "word_index = imdb.get_word_index()\n",
    "embedding_matrix = load_glove_embeddings(glove_path, word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "163ce675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_dim, input_length=max_review_length,\n",
    "                    weights=[embedding_matrix], trainable=False))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa643af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 100)          500000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 496, 64)           32064     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 248, 64)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 248, 64)           0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 248, 256)         197632    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 248, 256)          0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 128)              164352    \n",
      " nal)                                                            \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 894,177\n",
      "Trainable params: 394,177\n",
      "Non-trainable params: 500,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "              metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "# Model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5df5df99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 863s 1s/step - loss: 0.6521 - accuracy: 0.5969 - precision: 0.6009 - recall: 0.5772 - val_loss: 0.7501 - val_accuracy: 0.5436 - val_precision: 0.5233 - val_recall: 0.9810 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 853s 1s/step - loss: 0.6017 - accuracy: 0.6652 - precision: 0.6647 - recall: 0.6666 - val_loss: 0.5626 - val_accuracy: 0.7081 - val_precision: 0.6864 - val_recall: 0.7662 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 715s 915ms/step - loss: 0.5449 - accuracy: 0.7201 - precision: 0.7178 - recall: 0.7253 - val_loss: 0.4974 - val_accuracy: 0.7557 - val_precision: 0.7486 - val_recall: 0.7698 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 721s 923ms/step - loss: 0.4890 - accuracy: 0.7599 - precision: 0.7568 - recall: 0.7659 - val_loss: 0.4612 - val_accuracy: 0.7769 - val_precision: 0.7633 - val_recall: 0.8029 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 727s 930ms/step - loss: 0.4556 - accuracy: 0.7837 - precision: 0.7805 - recall: 0.7893 - val_loss: 0.4779 - val_accuracy: 0.7756 - val_precision: 0.7519 - val_recall: 0.8226 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 746s 954ms/step - loss: 0.4226 - accuracy: 0.8053 - precision: 0.8003 - recall: 0.8138 - val_loss: 0.4710 - val_accuracy: 0.7736 - val_precision: 0.7224 - val_recall: 0.8886 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 767s 981ms/step - loss: 0.4009 - accuracy: 0.8144 - precision: 0.8126 - recall: 0.8172 - val_loss: 0.5163 - val_accuracy: 0.7619 - val_precision: 0.6969 - val_recall: 0.9269 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 768s 983ms/step - loss: 0.3454 - accuracy: 0.8493 - precision: 0.8466 - recall: 0.8531 - val_loss: 0.4345 - val_accuracy: 0.8002 - val_precision: 0.7748 - val_recall: 0.8464 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 822s 1s/step - loss: 0.3304 - accuracy: 0.8547 - precision: 0.8539 - recall: 0.8559 - val_loss: 0.4434 - val_accuracy: 0.8012 - val_precision: 0.7761 - val_recall: 0.8465 - lr: 5.0000e-04\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 796s 1s/step - loss: 0.3190 - accuracy: 0.8624 - precision: 0.8576 - recall: 0.8690 - val_loss: 0.4305 - val_accuracy: 0.8066 - val_precision: 0.7835 - val_recall: 0.8474 - lr: 5.0000e-04\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 805s 1s/step - loss: 0.3104 - accuracy: 0.8659 - precision: 0.8637 - recall: 0.8690 - val_loss: 0.4530 - val_accuracy: 0.7979 - val_precision: 0.7524 - val_recall: 0.8879 - lr: 5.0000e-04\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 813s 1s/step - loss: 0.3021 - accuracy: 0.8704 - precision: 0.8685 - recall: 0.8730 - val_loss: 0.4415 - val_accuracy: 0.8058 - val_precision: 0.8206 - val_recall: 0.7829 - lr: 5.0000e-04\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 820s 1s/step - loss: 0.2804 - accuracy: 0.8817 - precision: 0.8810 - recall: 0.8826 - val_loss: 0.4308 - val_accuracy: 0.8038 - val_precision: 0.8049 - val_recall: 0.8020 - lr: 5.0000e-04\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 834s 1s/step - loss: 0.2527 - accuracy: 0.8965 - precision: 0.8958 - recall: 0.8973 - val_loss: 0.4490 - val_accuracy: 0.8054 - val_precision: 0.8131 - val_recall: 0.7930 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 848s 1s/step - loss: 0.2448 - accuracy: 0.8975 - precision: 0.8948 - recall: 0.9009 - val_loss: 0.5014 - val_accuracy: 0.7929 - val_precision: 0.7448 - val_recall: 0.8913 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                    epochs=20, batch_size=32, callbacks=[early_stopping, lr_scheduler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "601f0b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.66%\n",
      "Precision: 78.35%\n",
      "Recall: 84.74%\n",
      "782/782 [==============================] - 248s 316ms/step\n",
      "F1-Score: 81.42%\n",
      "Saved model to disk\n",
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Accuracy: {scores[1]*100:.2f}%\")\n",
    "print(f\"Precision: {scores[2]*100:.2f}%\")\n",
    "print(f\"Recall: {scores[3]*100:.2f}%\")\n",
    "\n",
    "# Calculate F1-score\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-Score: {f1*100:.2f}%\")\n",
    "\n",
    "# Save the model\n",
    "model.save('sentiment_analysis_model_improved.h5')\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# Optional: Load and verify the model\n",
    "loaded_model = tf.keras.models.load_model('sentiment_analysis_model_improved.h5')\n",
    "print(\"Model Loaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
